OPENAI_API_KEY=
OPENAI_BASE_URL=http://127.0.0.1:8999  # OpenAI 兼容 API（如需要会自动使用 /v1）
TAVILY_API_KEY=
DOC_PATH=./my-docs

# 生产建议的基础配置（按需开启）
# -------------------------------------------------
# API_KEY=  # 若设置，将要求在请求头里携带 X-API-Key 或 Authorization: Bearer
# CORS_ALLOW_ORIGINS=http://localhost:3000,http://127.0.0.1:3000
# CORS_ALLOW_CREDENTIALS=false
# MAX_UPLOAD_MB=25
# STRICT_ENV=false  # true 时启动即校验所需密钥
# REQUIRED_ENV=  # 额外强制检查的环境变量，逗号分隔
# REQUEST_LOGGING=true
# LOGGING_LEVEL=INFO
# LOG_TO_FILE=true
# LOG_FILE_MAX_BYTES=10485760
# LOG_FILE_BACKUP_COUNT=5
# DISABLE_RUNTIME_PIP=true  # 禁用运行时自动 pip 安装
# ENABLE_RUNTIME_PIP=false  # 若为 true（且 DISABLE_RUNTIME_PIP 不为 true），允许在受信环境中运行时自动 pip 安装
# RELOAD=false

# WebSocket
# ---------------------
# ALLOW_WS_API_KEY_QUERY=false  # 若为 true，允许 /ws?api_key=...（不建议，易被日志/历史泄露）

# NEXT_PUBLIC_GPTR_API_URL=http://0.0.0.0:8000  # 如未设置则默认为 localhost:8000
# GPTR_API_KEY=  # Next.js 服务端转发到后端的 API Key（不暴露给浏览器）
# NEXT_PUBLIC_GPTR_WS_API_KEY=  # 若需要浏览器直连 WS 且后端要求 API_KEY，则填此值（会暴露在前端）

# 爬虫配置
# ---------------------
# 控制并发爬取和速率限制以遵守 API 限制

# 最大并发爬虫工作线程数（同时进行的操作数）
# 根据你的爬虫服务限制进行调整：
#   - Firecrawl 免费版：2 个并发浏览器
#   - Firecrawl 爱好版：5 个并发浏览器
#   - BeautifulSoup/其他爬虫：根据目标网站限制设置
# 默认值：15（对于有速率限制的 API 可能过高）
#MAX_SCRAPER_WORKERS=15

# 速率限制：爬虫请求之间的最小间隔秒数
# 控制请求频率以避免超过 API 速率限制
# 计算方式：60 / 每分钟请求数
# 示例：
#   - Firecrawl 免费版（10 请求/分钟）：6.0 秒
#   - Firecrawl /scrape（10 请求/分钟）：6.0 秒
#   - 自定义 API（30 请求/分钟）：2.0 秒
#   - 无速率限制：0（默认）
# 注意：适用于所有爬虫（firecrawl、bs、browser 等）
# 默认值：0.0（无速率限制）
#SCRAPER_RATE_LIMIT_DELAY=0.0
